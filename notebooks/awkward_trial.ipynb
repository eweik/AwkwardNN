{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AwkwardNN: trial 1\n",
    "\n",
    "Get awkward toy data\n",
    "\n",
    "- Focus on just nested and jagged arrays\n",
    "- Assign maximum possible length and max possible depth for all arrays.\n",
    "    * Randomly pick max length/depth from range [1, max] for each event\n",
    "    and again for each sublist/nested list.\n",
    "- Binary targets: $$0, 1$$\n",
    "- Signal data drawn from\n",
    "    * $$\\mathcal{N}(-5, 1)$$ for target 0,\n",
    "    * $$\\mathcal{N}(+5, 1)$$ for target 1\n",
    "- Noise data: drawn from uniform dist $$U(-5, +5)$$\n",
    "- Assign probabilities for possible elements in array. Example:\n",
    "    * $$p($$ signal $$) = 0.50$$\n",
    "    * $$p($$ noise $$) = 0.10$$\n",
    "    * $$p($$ subarray $$) = 0.40$$\n",
    "- Starting with empty list, randomly sample elements until max length\n",
    "is reached. When max depth is reached, only sample from p(signal)\n",
    "and p(noise)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [5.18062093 5.26060132]\n",
      "0: [[-5.1770319427551 [-5.249777553149272]] [-6.428149829630505 [-5.001456527756981] -4.530484373970613]]\n",
      "0: [[-5.431717596774417] [-7.1512124491265165]]\n"
     ]
    }
   ],
   "source": [
    "import awkward\n",
    "from awkwardNN.createAwkwardData import generate_data_target\n",
    "\n",
    "max_len = 3\n",
    "max_depth = 3\n",
    "p_signal = 0.50\n",
    "p_noise = 0.10\n",
    "p_subarray = 0.40\n",
    "num_events = 3\n",
    "\n",
    "data, targets = generate_data_target(num_events=num_events,\n",
    "                                     prob_nest=p_subarray,\n",
    "                                     prob_sig=p_signal,\n",
    "                                     prob_bkg=p_noise,\n",
    "                                     max_len=max_len,\n",
    "                                     max_depth=max_depth)\n",
    "\n",
    "for i in range(num_events):\n",
    "    print(\"{}: {}\".format(targets[i], data[i]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create configuration namespace object to assign arbitrary values for NN\n",
    "parameters such as size of hidden layers, number of training epochs,\n",
    "learning rate, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 32\n",
      "train_size: 10000\n",
      "valid_size: 1000\n",
      "test_size: 1000\n",
      "batch_size: 1\n",
      "prob_nest: 0.3\n",
      "prob_signal: 0.65\n",
      "prob_noise: 0.05\n",
      "max_len: 5\n",
      "max_depth: 5\n",
      "train: True\n",
      "learning_rate: 0.0003\n",
      "epochs: 100\n",
      "momentum: 0.9\n",
      "train_patience: 10\n",
      "lr_decay_step: 10\n",
      "lr_decay_factor: 0.1\n",
      "random_seed: 1\n",
      "resume_training: False\n",
      "load_best: True\n",
      "plot_dir: ./plot\n",
      "ckpt_dir: ./ckpt\n",
      "print_freq: 100\n"
     ]
    }
   ],
   "source": [
    "from awkwardNN.config import get_config\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "config, _ = get_config()\n",
    "\n",
    "np.random.seed(config.random_seed)\n",
    "torch.manual_seed(config.random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(config.random_seed)\n",
    "\n",
    "config_dict = vars(config)\n",
    "for i in config_dict:\n",
    "    print(i + \": {}\".format(config_dict[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pytorch dataloader for neural net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "\n",
    "from awkwardNN.preprocessAwkwardData import get_dataloader\n",
    "\n",
    "trainloader = get_dataloader(\n",
    "    dataset_size=config.train_size, batch_size=config.batch_size,\n",
    "    prob_nest=config.prob_nest, prob_signal=config.prob_signal,\n",
    "    prob_noise=config.prob_noise, max_len=config.max_len,\n",
    "    max_depth=config.max_depth\n",
    ")\n",
    "validloader = get_dataloader(\n",
    "    dataset_size=config.valid_size, batch_size=config.batch_size,\n",
    "    prob_nest=config.prob_nest, prob_signal=config.prob_signal,\n",
    "    prob_noise=config.prob_noise, max_len=config.max_len,\n",
    "    max_depth=config.max_depth\n",
    ")\n",
    "dataloader = (trainloader, validloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create pytorch neural net\n",
    "\n",
    "First trial network: flattening all the data from an event into one list and passing through an RNN.\n",
    "Loses information from nesting structure.\n",
    "\n",
    "Second trial network:\n",
    "- Recurrent neural network with a layer for each nested level of data.\n",
    "- RNN processes an event one nested level at a time, passing each level through its associated layer in order from highest level to lowest level.\n",
    "- Append hidden state to input for each layer, then use hidden state for through final output layer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AwkwardNN(nn.Module):\n",
    "    def __init__(self, max_depth, input_sz, hidden_sz, output_sz):\n",
    "        super(AwkwardNN, self).__init__()\n",
    "        self.max_depth = max_depth\n",
    "        self.input_sz = input_sz\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.layers = []\n",
    "        for _ in range(max_depth):\n",
    "            self.layers.append( nn.Linear(input_sz + hidden_sz, hidden_sz) )\n",
    "        self.output = nn.Linear(hidden_sz, output_sz)\n",
    "\n",
    "    def forward(self, input_data, markers, hidden):\n",
    "        i = 0\n",
    "        # since we're not iterating over batches\n",
    "        input_data, markers = input_data[0], markers[0]\n",
    "        for marker, net_layer in zip(markers, self.layers):\n",
    "            if marker == 0:\n",
    "                continue\n",
    "            for _ in range(marker):\n",
    "                x = torch.tensor([[input_data[i]]], dtype=torch.float32)\n",
    "                combined = torch.cat((x, hidden), 1)\n",
    "                hidden = F.relu(net_layer(combined))\n",
    "                i += 1\n",
    "        output = F.log_softmax(self.output(hidden), dim=1)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train neural net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/100\n",
      "Train Epoch: 1 [100/10000 (1%)]\tLoss: 0.648371\tAcc: 100%\n",
      "Train Epoch: 1 [200/10000 (2%)]\tLoss: 0.599288\tAcc: 100%\n",
      "Train Epoch: 1 [300/10000 (3%)]\tLoss: 0.875415\tAcc: 0%\n",
      "Train Epoch: 1 [400/10000 (4%)]\tLoss: 0.667942\tAcc: 100%\n",
      "Train Epoch: 1 [500/10000 (5%)]\tLoss: 0.654171\tAcc: 100%\n",
      "Train Epoch: 1 [600/10000 (6%)]\tLoss: 0.524788\tAcc: 100%\n",
      "Train Epoch: 1 [700/10000 (7%)]\tLoss: 0.502989\tAcc: 100%\n",
      "Train Epoch: 1 [800/10000 (8%)]\tLoss: 0.909538\tAcc: 0%\n",
      "Train Epoch: 1 [900/10000 (9%)]\tLoss: 0.645407\tAcc: 100%\n",
      "Train Epoch: 1 [1000/10000 (10%)]\tLoss: 0.538581\tAcc: 100%\n",
      "Train Epoch: 1 [1100/10000 (11%)]\tLoss: 0.710282\tAcc: 0%\n",
      "Train Epoch: 1 [1200/10000 (12%)]\tLoss: 0.412489\tAcc: 100%\n",
      "Train Epoch: 1 [1300/10000 (13%)]\tLoss: 0.386862\tAcc: 100%\n",
      "Train Epoch: 1 [1400/10000 (14%)]\tLoss: 0.619756\tAcc: 100%\n",
      "Train Epoch: 1 [1500/10000 (15%)]\tLoss: 0.451084\tAcc: 100%\n",
      "Train Epoch: 1 [1600/10000 (16%)]\tLoss: 0.486227\tAcc: 100%\n",
      "Train Epoch: 1 [1700/10000 (17%)]\tLoss: 0.486832\tAcc: 100%\n",
      "Train Epoch: 1 [1800/10000 (18%)]\tLoss: 0.715655\tAcc: 0%\n",
      "Train Epoch: 1 [1900/10000 (19%)]\tLoss: 0.329037\tAcc: 100%\n",
      "Train Epoch: 1 [2000/10000 (20%)]\tLoss: 0.368602\tAcc: 100%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-25d9429f783e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mavg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mavg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-29-25d9429f783e>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\nEpoch: {}/{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m         \u001B[0mtrain_one_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m         \u001B[0mvalid_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate_one_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mbest_valid_acc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbest_valid_acc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-29-25d9429f783e>\u001B[0m in \u001B[0;36mtrain_one_epoch\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m     33\u001B[0m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_hat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m             \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_accuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_hat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m             \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    196\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m         \"\"\"\n\u001B[0;32m--> 198\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    199\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m     98\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m     99\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 100\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import awkwardNN.utils as utils\n",
    "\n",
    "model = AwkwardNN(max_depth=config.max_depth,\n",
    "                  input_sz=1,\n",
    "                  hidden_sz=config.hidden_size,\n",
    "                  output_sz=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "def train():\n",
    "    best_valid_acc = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        print('\\nEpoch: {}/{}'.format(epoch+1, config.epochs))\n",
    "        train_one_epoch(epoch)\n",
    "        valid_loss, valid_acc = validate_one_epoch(epoch)\n",
    "        best_valid_acc = max(valid_acc, best_valid_acc)\n",
    "        utils.print_valid_stat(valid_loss, valid_acc, config.valid_size, best_valid_acc)\n",
    "    return\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    losses, accs = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.train()\n",
    "    for i, (x, marker, y) in enumerate(trainloader):\n",
    "        x, marker, y = x.to(device), marker.to(device), y.to(device)\n",
    "        hidden = torch.zeros(config.batch_size, config.hidden_size)\n",
    "        hidden = hidden.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            y_hat, hidden = model(x, marker, hidden)\n",
    "            loss = utils.get_loss(y, y_hat)\n",
    "            acc = utils.get_accuracy(y, y_hat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            accs.update(acc.item(), x.size(0))\n",
    "\n",
    "        if i % config.print_freq == 0:\n",
    "            utils.print_train_stat(epoch+1, i+config.print_freq, x, config.train_size, loss, acc)\n",
    "    return losses.avg, accs.avg\n",
    "\n",
    "\n",
    "def validate_one_epoch(epoch):\n",
    "    losses, accs = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.eval()\n",
    "    for i, (x, marker, y) in enumerate(validloader):\n",
    "        x, marker, y = x.to(device), marker.to(device), y.to(device)\n",
    "        hidden = torch.zeros(config.batch_size, config.hidden_size)\n",
    "        hidden = hidden.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat, _ = model(x, marker, hidden)\n",
    "            loss = utils.get_loss(y, y_hat)\n",
    "            acc = utils.get_accuracy(y, y_hat)\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            accs.update(acc.item(), x.size(0))\n",
    "    return losses.avg, accs.avg\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or you can run `main.py`\n",
    "\n",
    "Current issues/problems:\n",
    "\n",
    "- Pytorch only takes in `Tensor` objects, which have to be rectangular like numpy arrays\n",
    "- Varying length arrays â†’ hard to batch data\n",
    "    - because `Tensor` objects have to be rectangular\n",
    "    - Could zero pad and then ignore those zeros\n",
    "    - Currently: go through data one event at a time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}