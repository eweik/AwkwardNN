{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Awkward NN Trial 2\n",
    "\n",
    "## Get ROOT Data\n",
    "\n",
    "### First naive approach at getting data:\n",
    "\n",
    "- The data is stored in column/feature format on ROOT files\n",
    "\n",
    "- But we want (I assume) to pass data through the network in row/event format\n",
    "\n",
    "- So, beforehand, I convert from column to row based data as I\n",
    "read it in.\n",
    "\n",
    "    - But, this is kind of slow since I have to iterate\n",
    "      through each row in each column. Currently, awkward-array does\n",
    "      not support this type of operation in a vectorized manner.\n",
    "\n",
    "- Result: a list of events, each with varying numbers of particles\n",
    "and where each particle has varying numbers of fields.\n",
    "\n",
    "- Note: Some fields are interesting in that...\n",
    "\n",
    "    - they are also nested, e.g. for an event that has 3 jets, the field known\n",
    "      as `Jet.Mass` has 3 floating pt numbers (one for each jet), but the\n",
    "      field  `Jet.Tau[5]` has 3 vectors of length five. So, when I convert this\n",
    "      field to row/event format, I flatten it such that five numbers are added to\n",
    "      the jet instead of 1 5-vector.\n",
    "\n",
    "    - the size of the vector associated with the field is a constant multiple of\n",
    "      the number of expected fields, e.g. an event with 3 jets has a field\n",
    "      `Jets.TrimmedP4[5]` with 15 floating pt numbers. So when I convert this,\n",
    "      I add the first 5 to the first jet, the next 5 to the second jet, and so\n",
    "      on. I do this with all such types of fields, checking that:\n",
    "      ```len(field) % (# of subevents) == 0```\n",
    "\n",
    "    - some fields have varying lengths, e.g. while each jet has 1 `Jet.Mass`\n",
    "      and 5 `Jets.TrimmedP4[5]`, it has a variable number\n",
    "      of `Jets.Constituents`, thus making it \"double-jagged\"\n",
    "\n",
    "- Note: For the field of type `TLorentzVector`, I exchange this field for its associated energy `E` attribute. Although this can of course be changed.\n",
    "\n",
    "- Note: current `uproot` memory issue reading in the following features:\n",
    "    - b'Particle.fBits'\n",
    "    - b'Track.fBits'\n",
    "    - b'Tower.fBits'\n",
    "    - b'EFlowTrack.fBits'\n",
    "    - b'EFlowPhoton.fBits'\n",
    "    - b'EFlowNeutralHadron.fBits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import uproot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from awkwardNN.preprocessRoot import get_events\n",
    "from awkwardNN.awkwardNN import awkwardNN\n",
    "\n",
    "tree1 = uproot.open(\"../data/test_qcd_1000.root\")[\"Delphes\"]\n",
    "tree2 = uproot.open(\"../data/test_ttbar_1000.root\")[\"Delphes\"]\n",
    "\n",
    "# Get data that is \"double-jagged\":\n",
    "# e.g. every event has a varying number of jets and every jet has a varying number of fields\n",
    "varying_fields = [\"Jet*\"]\n",
    "X1 = get_events(tree1, varying_fields)\n",
    "X2 = get_events(tree2, varying_fields)\n",
    "y1 = [1] * len(X1)\n",
    "y2 = [0] * len(X2)\n",
    "X = X1 + X2\n",
    "y = y1 + y2\n",
    "X_train_double_jagged, X_test_double_jagged, y_train_double_jagged, y_test_double_jagged = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Get data that is \"single-jagged\": i.e. every\n",
    "# fields such that every particle in every event has the same number of fields\n",
    "fixed_fields = ['Particle.E', 'Particle.P[xyz]']\n",
    "X1 = get_events(tree1, fixed_fields)\n",
    "X2 = get_events(tree2, fixed_fields)\n",
    "X = X1 + X2\n",
    "X_train_single_jagged, X_test_single_jagged, y_train_single_jagged, y_test_single_jagged = train_test_split(X, y, test_size=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create and train pytorch neural net\n",
    "\n",
    "2 types of AwkwardNNs so far: RNN/LSTM/GRU and Deepset\n",
    "\n",
    "### For RNN single jagged - training procedure (essentially like a normal RNN)\n",
    "- For each event:\n",
    "    - Initialize hidden state\n",
    "    - For each particle\n",
    "        - Pass particle + hidden state through RNN\n",
    "\n",
    "### For RNN double jagged - training procedure (1 RNN with 2 hidden states)\n",
    "\n",
    "- For each event:\n",
    "    - Initialize first hidden state\n",
    "    - For each particle\n",
    "        - Initialize second hidden state\n",
    "        - For each feature in particle\n",
    "            - Pass feature + hidden states through RNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use keyword argument `mode` to specify whether it is an `rnn`, `lstm`, `gru`, or `deepset` (next section)\n",
    "\n",
    "# use keyword argument `feature_size_fixed` to distinguish between single-jagged RNN (feature_size_fixed=True)\n",
    "# and double-jagged RNN (feature_size_fixed=True (default))\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# single jagged\n",
    "rnn_single_jagged = awkwardNN(mode='rnn', max_iter=num_epochs, verbose=True, feature_size_fixed=True)\n",
    "rnn_single_jagged.train(X_train_single_jagged, y_train_single_jagged)\n",
    "rnn_single_jagged.test(X_test_single_jagged, y_test_single_jagged)\n",
    "\n",
    "\n",
    "# double jagged\n",
    "rnn_double_jagged = awkwardNN(mode='rnn', max_iter=num_epochs, verbose=True, feature_size_fixed=False)\n",
    "rnn_double_jagged.train(X_train_double_jagged, y_train_double_jagged)\n",
    "rnn_double_jagged.test(X_test_double_jagged, y_test_double_jagged)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For Deepset single jagged - training procedure (like a normal deepset)\n",
    "\n",
    "- 2 networks: phi network and rho network\n",
    "- For each event:\n",
    "    - For each particle:\n",
    "        - Pass particle through phi network\n",
    "    - Sum outputs from phi network\n",
    "    - Pass sum through rho network\n",
    "\n",
    "### For Deepset double jagged - training procedure (essentially 2 Deepsets stacked on each other)\n",
    "\n",
    "- One deepset for particles in events\n",
    "- One deepset for features in particle\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# single jagged\n",
    "rnn_single_jagged = awkwardNN(mode='deepset', max_iter=num_epochs, verbose=True, feature_size_fixed=True)\n",
    "rnn_single_jagged.train(X_train_single_jagged, y_train_single_jagged)\n",
    "rnn_single_jagged.test(X_test_single_jagged, y_test_single_jagged)\n",
    "\n",
    "\n",
    "# double jagged\n",
    "rnn_double_jagged = awkwardNN(mode='deepset', max_iter=num_epochs, verbose=True, feature_size_fixed=False)\n",
    "rnn_double_jagged.train(X_train_double_jagged, y_train_double_jagged)\n",
    "rnn_double_jagged.test(X_test_double_jagged, y_test_double_jagged)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}